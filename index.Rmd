---
title: "IODS course project"
author:
- "Noora Sheridan"
- "noora.sheridan@aalto.fi"
date: 5.3.2017
output:
  html_document:
    theme: yeti
    toc: true
    toc_depth: 2
    fig_caption: true
    fig_width: 6
    fig_height: 4
    code_folding: hide
    warning: FALSE
    message: FALSE
---

## Abstract

In this assignment I study the results of Helsinki Region Transport (HSL) customer satisfaction survey to see how customer service, punctuality of transportation, space available, meeting customers' travel needs, tidyness of transportation, and ease of changing routes relate to high satisfaction levels with HSL. In this assignment I use logistic regression to analyse how the different variables relate to high satisfaction with HSL, and to create a model used to classify observations by predicting whether a customer has high satisfaction with HSL or not. High satisfaction is defined as overall grade 4 or 5 in a scale of 1 to 5 given to HSL.

The findings of this assignment are that all the variables studied are positively related to high satisfaction, with customer service having the highest odds ratio and space the lowest. The predictive power of the model created is fairly good (about 88% of observations are classified correctly). One of the key benefits of the findings to HSL is that the model created could enable fairly accurate predictions of customer satisfaction through gathering data from HSL's operations, thus HSL could get an indication about satisfaction levels on different routes without the need to rely on customer satisfaction surveys, and take more timely action. The second benefit is that HSL could use information about the odds ratios of different variables to choose which factors to focus on (e.g. to emphasis customer service skills on recruitment and selection).


## Overview of the research

In this assignment I am analysing Helsinki Region Transport (HSL) customer satisfaction survey. This dataset has been wrangled to meet the needs of my analysis, and the wrangling script is available [here](https://github.com/v-a-l-a/IODS-final/blob/master/creating_hsl.R). I will use the logistic regression method to see whether or not specific variables such as availability of seats and punctuality of transport explain the target variable overall grade given to HSL. The aim is to identify which factors contribute the most to high satisfaction with HSL. High satisfaction is defined as overall grade 4 or 5 out of 5 given to HSL.

**Research question**: Which of the following variables are contributing the most towards high satisfaction with HSL: customer service, punctuality of transportation, availability of seats (space), transportation meeting travel needs, tidyness of busses / carriages etc. and ease of changing routes?

**My hypothesis**: All of the variables are positively related to overall grade given to HSL, but some more than others:

+ Customer service: small effect (not many interact with e.g. the bus driver)
+ Punctuality: large effect (transportation running on time seen as important)
+ Space: small effect (not of key importance for many)
+ Meeting travel needs: very large effect (very important to customers)
+ Tidyness: small effect (not very important)
+ Ease of changing: medium effect (important to some but not to others)

## The HSL dataset

The original dataset includes all responses to the HSL customer satisfaction survey openly available [here](https://hsl.louhin.com/asty/help). The original dataset has 340 378 observations and 127 variables, with the variables relating to the respondents (e.g. age, gender, occupation), to their travel (e.g. frequency of use of current bus / train, access to a car), to their opinion about HSL transportation (e.g. customer service, tidyness of busses etc., overall grade given to HSL) and to other factors such as how they search for information about timetables or pay for their journeys.

The first task in my data wrangling was to choose the variables to analyse because of the large number of variables and observations in the original dataset. Moreover, when exploring the variables, I noticed that some of them had a lot of missing values. For example the variable 'K1A8L' (the ferry's timetables suit my travel needs) has over 331 000 missing answers, probably explained by the fact that not many people use a ferry on day-to-day travel. However, the variable 'K3B' (overall grade for HSL-region public transport) is only missing some 10 000 responses out of over 340 000.

I kept interesting variables that I suspect are related to satisfaction with HSL, as well as of course the target variable of my study, 'High_grade'. I chose for my analysis 6 different predictor variables based on the critetion that they didn't have many missing observations and that they relate to things HSL could fairly easily change (e.g. provide more customer service training or tidy the busses more often or more thoroughly). This allows me to compare the effects these variables have on satisfaction with HSL so that it is possible to give suggestions about which things to prioritise to improve customer satisfaction.

Here are the variables chosen for this study and the statements / questions relating to them:

``` {r colnames hsl}
hsl <- read.table("/Users/Noora/Documents/IODS-project/IODS-final/create_hsl.txt", header = TRUE)
colnames(hsl)
```

+ **Customer_service**: drivers / personnel give friendly customer service
+ **Punctuality**: busses / carriages / ferries run according to timetable
+ **Space**: there are seats available on this route at this time of the day
+ **Meets_needs**: the route / metro / local train meets my travel needs
+ **Tidyness**: busses / carriages / ferries are tidy
+ **Changing**: changing to another route is easy
+ **High_grade**: overall grade given to HSL-region transportation

All the variables (except for high grade) have values between 1 and 5, with 1 = very badly, 5 = very well (i.e. they use a 5-level Likert scale). After choosing the variables described above for my analysis, I removed all observations with missing values from my dataset called 'hsl'. This reduced the number of observations but I was still left with 225 492 observations for my HSL dataset!

``` {r hsl dimensions}
dim(hsl)
```

I renamed all the variables to be more descriptive. I also created the variable 'High_Grade' from variable 'Grade' by setting high grade to be true if the overall grade given to HSL was either 4 or 5 when 5 = 'very good' and 1 = 'very bad'. After this I removed the original 'Grade' variable from my dataset. Lastly I saved the dataset in my local folder.

## Exploring the variables

Next I will look at summaries of the variables to get an idea of how they are distributed.

``` {r hsl overview of variables}
knitr::kable(summary(hsl))
```

*Table 1: Summaries of the variables*


It is clear that the majority of customers are very satisfied with HSL, with there being over 190 000 highly satisfied customers compared to about 32 000 not highly satisfied. It seems that all the predictor variables take on very high values in general. The mean for all the predictor variables is between approx. 3.9 and 4.5, thus it is clear HSL is in general doing very well with different factors such as availability of seats on routes or meeting customers' needs. All of these  variables are distributed between 1 and 5, but the first quartile values are very high (3 or 4) so only 25% of respondents have given lower values for the variables.

``` {r hsl summaries of the variables, warning = (FALSE)}
library(ggplot2)
library(tidyr)
gather(hsl) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
```

*Figure 1: Overview of the distribution of the variables*

This visualisation shows that all the predictor variables have very few low values (1 or 2), but that they differ in terms of how many customers have rated the variable 4 or 5. For example when looking at 'Meets_needs', clearly the largest bar is that corresponding to value 5, whereas for 'Customer_service' clearly the largest is 4, and 5 is even a bit lower than 3. For changing 4 and 5 are fairly equal height (meaning that there are roughly equal amount of observations with changing 4 and changing 5, although there are a bit more for 4 as it is a bit higher).

Next I will look at whether the average scores given for each variable differ between those who are highly satisfied and those who are not.

``` {r comparing means, message = (FALSE)}
library(dplyr)
library(knitr)
crosstab1 <- hsl %>% group_by(High_grade) %>% summarise(mean_service = round(mean(Customer_service), 1), mean_punct = round(mean(Punctuality), 1), mean_space = round(mean(Space), 1), mean_needs = round(mean(Meets_needs), 1), mean_tidy = round(mean(Tidyness), 1), mean_chang = round(mean(Changing), 1))
knitr::kable(crosstab1)
```

*Table 2: The differences between the mean values of variables between highly and not highly satisfied customers*

From this I see that for all variables, the average score given by highly satisfied customers is higher than the average score given by not highly satisfied customers. However, for some variables the differences are larger than for others, with punctuality and changing having a 0.8 point difference whereas space only has a 0.3 point difference.

I will now explore in more depth how the predictor variables relate to high satisfaction.

``` {r hsl first plots, message = (FALSE)}
C1 <- ggplot(hsl, aes(x = Customer_service, fill = High_grade))
P1 <- ggplot(hsl, aes(x = Punctuality, fill = High_grade))
S1 <- ggplot(hsl, aes(x = Space, fill = High_grade))
M1 <- ggplot(hsl, aes(x = Meets_needs, fill = High_grade))
T1 <- ggplot(hsl, aes(x = Tidyness, fill = High_grade))
Ch1 <- ggplot(hsl, aes(x = Changing, fill = High_grade))

library(lattice)
library(gridExtra)
C <- C1 + geom_bar(position = "fill") + ggtitle("Customer service") + scale_fill_brewer(palette = "YlOrRd", guide = F)
P <- P1 + geom_bar(position = "fill") + ggtitle("Punctuality") + scale_fill_brewer(palette = "YlOrRd", guide = F)
S <- S1 + geom_bar(position = "fill") + ggtitle("Space") + scale_fill_brewer(palette = "YlOrRd", guide = F)
M <- M1 + geom_bar(position = "fill") + ggtitle("Meeting needs") + scale_fill_brewer(palette = "YlOrRd", guide = F)
Ti <- T1 + geom_bar(position = "fill") + ggtitle("Tidynes") + scale_fill_brewer(palette = "YlOrRd", guide = F)
Ch <- Ch1 + geom_bar(position = "fill") + ggtitle("Changing") + scale_fill_brewer(palette = "YlOrRd") + theme(legend.position = "bottom")

g_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)}

plotlegend<-g_legend(Ch)

grid.arrange(C, P, S, M, nrow = 2)
grid.arrange(Ti, Ch + theme(legend.position = "none"), nrow = 2, plotlegend, ncol = 2, bottom = "Figure 2: Proportions of high grade")
```

It is clear that all of the variables seem to be related to high grade. For example for the variable 'Changing', very large proportion of customers who rate changing as 5 are highly satisfied with HSL, but for those who rate changing as 1, a much smaller proportion of customers are highly satisfied. The same is true for all the other variables. The main difference seen in these plots is that for some variables, even when the variable has value 1, the proportions of highly satisfied and not highly satisfied customers are faily even (e.g. for space), whereas for other variables proportionally more customers seem to be not highly satisfied at the variable's value 1 (e.g. changing).

## Logistic regression analysis

Logistic regression analysis can be used to identify factors related to the target variable, in this case high satisfaction with HSL. It can also be useful to predict customers who have high satisfaction with HSL (and who don't). This can be useful because HSL should be able to gather information about e.g. how well specific routes run on time, how often specific busses or other transportation are cleaned etc. and thus be able to predict how satisfied customers are with a logistic regression model created. If the model predicts customers are not very satisfied on specific routes, HSL can take action to improve factors related to high satisfaction.

With logistic regressions, I can obtain odds ratios for each variable. The odds ratios are the exponents of each variable's coefficient obtained with logistic regression analysis. In my model, the odds ratio of a variable describes the % increase in the odds of having high satisfaction with HSL for a one-unit increase in the variable in question, holding all other variables in the model fixed.

## The results of analysis

``` {r logistic reg}
m <- glm(High_grade ~ ., data = hsl, family = "binomial")
summary(m)
```

From the summary of my logitic regression, I see that all the variables are clearly statistically significant (the p values are extremely low, well below 0.05). Thus there is no evidence suggesting that I should remove any of the variables from my model. Next, I will look at the odds ratios for the variables so that I can interpret the coefficients.

``` {r odds ratios, warning = (FALSE)}
odds_ratio <- coef(m) %>% exp
conf_I <- confint(m) %>% exp
cbind(odds_ratio, conf_I)
```

*Table 3: Odds ratios of the variables*

From the output I can see that none of the variables'  95% confidence intervals (CI) include 1. This further demonstrates that they should be kept in the model, as all of them are related to high satisfaction. All of the predictor variables' odds ratios are above 1, meaning that they are positively related with high grade. The differences between the variables are not very large, none of the odds ratios are below 1 or above 2. The confidence intervals of all of the variables are very small, showing that we can be fairly confident that the estimated odds ratios are accurate. 

Customer service has the highest odds ratio - when it increases by 1, the odds of a person being highly satisfied (has given HSL a high grade) with HSL almost double as they increase by around 1.96 times (so by 96%) when the other variables are kept fixed. The second highest odds ratio is that of changing, being 1.79, and the lowest odds ratio is that off space. For space, 1 unit increase in space increases the odds of being highly satisfied by only 1.12 so about 12%. It seems that punctuality, meeting needs, and tidyness are roughly as important, with a unit change in any one of them (whilst keeping all the other predictor variables fixed), increases the odds of being highly satisfied by about 1.5 times.

## Model validation

Next I will look at the predictive power of my model.

``` {r predictions}
probabilities <- predict(m, type = "response")
hsl_pred <- mutate(hsl, probability = probabilities)
hsl_pred <- mutate(hsl_pred, prediction = probabilities > 0.5)
table1 <- table(High_grade = hsl_pred$High_grade, prediction = hsl_pred$prediction)
table1
table2 <- prop.table(table1, 2)*100
table2 <- round(table2, 1)
addmargins(table2, margin = 1)
```

*Tables 4 & 5: Predictions about high grade*

The model seems to be quite good at predicting high satifaction! However, it does predict approx. 24 000 observations that have actually not given HSL a high grade to have given a high grade. However, from table X I see that of those observations predicted to have given HSL a high grade, 89% were correct, and only 11% wrong. Out of those predicted to not have given HSL a high grade, 67% were correct, but 33%, i.e. a third, were incorrect. Thus in % terms the model's predictions about high grade are quite accurate, whereas its predictions about not high grade are less accurate.

To get a better idea of the accuracy of my model in general, I next look at the average number of inaccurately classified observations in the data.
``` {r loss function}
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}
loss_func(class = hsl_pred$High_grade, prob = hsl_pred$probability)
```

The proportion of inaccurately classified observations is 12.4%. This means that about 1 out of 8 observations are classified wrong. However, the performance of the model is good, the model seems to be quite good at predictions.

I will also see the results of 10-fold cross-validation on the model to test the model on unseen data to get an indication of the actual predictive power of the model.

``` {r cross validation, message = (FALSE)}
library(boot)
cross_v <- cv.glm(data = hsl_pred, cost = loss_func, glmfit = m, K = 10)
cross_v$delta[1]
```

Now, the proportion of inaccurately classified observations is 12.5%, so roughly the same as the 12.4% obtained above. I can conclude that the model is fairly accurate.

## Conclusion and discussion

The results of the analysis have produced a model that is fairly accurate at classifying observations correctly, with only classifying about 12.5% of observations incorrectly in 10-fold cross-validation. The logistic regression model has showed that all the variables in the study are positively associated with high grade given to HSL (i.e. high satisfaction). There are differences between the odds ratios for the variables, although all of them have odds ratios between above 1 and below 2.

It seems that customer service is the most strongly related with high satisfaction, with 1 unit increase in customer service leading to a nearly 2 fold increase in the odds of the customer being highly satisfied whilst keeping the other predictor variables fixed. The second highest odds ratio is that of changing, with it having an odds ratio of 1.79. After this, three variables - punctuality, meeting needs, and tidyness - have all roughyl 1.5 as odds ratios. The lowest odds ratio is clearly that of space with odds ratio of 1.12.

When comparing the results to my original hypotheses, I see that most of them were incorrect. As seen in the table below, only space having a small effect on high satisfaction was correct out of all of my hypotheses. Here, large effect means that the variable's odds ratio is higher than that of the other variables in general in the dataset rather than the absolute value of the odds ratio being extremely large.

| Variable | My hypothesis | Result | Correctness of hypothesis | 
|:-------|:-----:|:------:|:------:|
| Customer service | small effect | large | wrong | 
| Punctuality | large effect | medium | wrong | 
| Space | small | small | **correct** | 
| Meeting needs | very large effect | medium | wrong | 
| Tidyness | small effect | medium | wrong | 
| Changing | medium effect | large | wrong | 
*Table 6: Comparison of hypotheses and actual results*


The results have two implications for HSL. Firstly, it might be able to predict how satisfied customers are on specific routes without conducting a survey. It could assess how easy it is to change to another route, test the customer service skills of employees, and gather information about how well specific routes' transportation is on time, and conduct analysis of how tidy the busses / carriages etc. are. With the results of such analysis, it would be possible to predict with the model generated to get an idea of which routes' customers are likely to be the most or the least satisfied with HSL. This could enable HSL to take action immediately, rather than wait for the results of a customer satisfaction survey and then take action. Moreover, I assume much of the information needed to generate the predictions is already available to HSL, such as information about the condition of busses / carriages / ferries, and information about how well they are on time.

The second implication is that the results of the logistic regression analysis show which factors HSL should prioritise to improve customer satisfaction. The customer service skills of employees seem to relate the most to the odds of the person being satisfied with HSL. Thus HSL should pay particularly much attention to customer serice skills in recruitment and selection. Providing training on such skills could also be considered, as the employees' customer service skills were rated on average to be 3.9. Thus clearly most employees have fairly good customer service skills, but at the same time customer service is perhaps the variable with the smallest proportion of observations giving it 5 out of all the variables.

When planning new routes or changing existing ones, focus should be also on ease of change of routes. However, the results also show that the differences between the odds ratios related to different variables are not very large, thus HSL should also consider how easy it is to change each factor, e.g. imrpoving tidyness may be easier than improving ease of changing. The main benefit of the results obtained is that they could give managers of HSL an indication of importance of the variables studied to high satisfaction.